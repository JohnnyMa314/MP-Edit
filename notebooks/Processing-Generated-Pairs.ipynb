{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance Datasets Between Original Labels\n",
    "\n",
    "Sample **by MNLI index** from list of minimal pair edits of mask-filled sentence pairs until classes are balanced.\n",
    "\n",
    "With replacement **by MNLI index** and without replacement **by Generated Sentence Pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000_fine-tuned_content-words_gold-label_beam_mnli_cond_pairs_tagged.csv\r\n",
      "5000_fine-tuned_content-words_gold-label_diverse-beam_mnli_cond_pairs_tagged.csv\r\n",
      "5000_fine-tuned_content-words_model-label_beam_mnli_cond_pairs_tagged.csv\r\n",
      "5000_fine-tuned_content-words_model-label_diverse-beam_mnli_cond_pairs_tagged.csv\r\n",
      "5000_fine-tuned_data-slices_gold-label_beam_mnli_cond_pairs_tagged.csv\r\n",
      "5000_fine-tuned_data-slices_gold-label_diverse-beam_mnli_cond_pairs_tagged.csv\r\n",
      "5000_fine-tuned_data-slices_model-label_beam_mnli_cond_pairs_tagged.csv\r\n",
      "5000_fine-tuned_data-slices_model-label_diverse-beam_mnli_cond_pairs_tagged.csv\r\n",
      "categories1.png\r\n",
      "cleaned_5000_fine-tuned_content-words_gold-label_beam_mnli_cond_pairs_tagged.csv\r\n",
      "cleaned_5000_fine-tuned_content-words_model-label_beam_mnli_cond_pairs_tagged.csv\r\n",
      "cleaned_5000_fine-tuned_data-slices_gold-label_beam_mnli_cond_pairs_tagged.csv\r\n",
      "cleaned_5000_fine-tuned_data-slices_gold-label_diverse-beam_mnli_cond_pairs_tagged.csv\r\n",
      "cleaned_5000_fine-tuned_data-slices_model-label_beam_mnli_cond_pairs_tagged.csv\r\n",
      "cleaned_5000_fine-tuned_data-slices_model-label_diverse-beam_mnli_cond_pairs_tagged.csv\r\n",
      "instances1.png\r\n",
      "label-flips1.png\r\n",
      "sample_5000_fine-tuned_content-words_gold-label_beam_mnli_cond_pairs_tagged.csv\r\n",
      "sample_5000_fine-tuned_content-words_model-label_beam_mnli_cond_pairs_tagged.csv\r\n",
      "sample_5000_fine-tuned_data-slices_gold-label_beam_mnli_cond_pairs_tagged.csv\r\n",
      "sample_5000_fine-tuned_data-slices_gold-label_diverse-beam_mnli_cond_pairs_tagged.csv\r\n",
      "sample_5000_fine-tuned_data-slices_model-label_beam_mnli_cond_pairs_tagged.csv\r\n",
      "sample_5000_fine-tuned_data-slices_model-label_diverse-beam_mnli_cond_pairs_tagged.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../output/MNLI/new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5000_fine-tuned_content-words_gold-label_beam_mnli_cond_pairs_tagged.csv',\n",
       " '5000_fine-tuned_content-words_gold-label_diverse-beam_mnli_cond_pairs_tagged.csv',\n",
       " '5000_fine-tuned_content-words_model-label_beam_mnli_cond_pairs_tagged.csv',\n",
       " '5000_fine-tuned_content-words_model-label_diverse-beam_mnli_cond_pairs_tagged.csv',\n",
       " '5000_fine-tuned_data-slices_gold-label_beam_mnli_cond_pairs_tagged.csv',\n",
       " '5000_fine-tuned_data-slices_gold-label_diverse-beam_mnli_cond_pairs_tagged.csv',\n",
       " '5000_fine-tuned_data-slices_model-label_beam_mnli_cond_pairs_tagged.csv',\n",
       " '5000_fine-tuned_data-slices_model-label_diverse-beam_mnli_cond_pairs_tagged.csv',\n",
       " 'categories1.png',\n",
       " 'cleaned_5000_fine-tuned_content-words_gold-label_beam_mnli_cond_pairs_tagged.csv',\n",
       " 'cleaned_5000_fine-tuned_content-words_model-label_beam_mnli_cond_pairs_tagged.csv',\n",
       " 'cleaned_5000_fine-tuned_data-slices_gold-label_beam_mnli_cond_pairs_tagged.csv',\n",
       " 'cleaned_5000_fine-tuned_data-slices_gold-label_diverse-beam_mnli_cond_pairs_tagged.csv',\n",
       " 'cleaned_5000_fine-tuned_data-slices_model-label_beam_mnli_cond_pairs_tagged.csv',\n",
       " 'cleaned_5000_fine-tuned_data-slices_model-label_diverse-beam_mnli_cond_pairs_tagged.csv',\n",
       " 'instances1.png',\n",
       " 'label-flips1.png',\n",
       " 'sample_5000_fine-tuned_content-words_gold-label_beam_mnli_cond_pairs_tagged.csv',\n",
       " 'sample_5000_fine-tuned_content-words_model-label_beam_mnli_cond_pairs_tagged.csv',\n",
       " 'sample_5000_fine-tuned_data-slices_gold-label_beam_mnli_cond_pairs_tagged.csv',\n",
       " 'sample_5000_fine-tuned_data-slices_gold-label_diverse-beam_mnli_cond_pairs_tagged.csv',\n",
       " 'sample_5000_fine-tuned_data-slices_model-label_beam_mnli_cond_pairs_tagged.csv',\n",
       " 'sample_5000_fine-tuned_data-slices_model-label_diverse-beam_mnli_cond_pairs_tagged.csv']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = !ls ../output/MNLI/new\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000_fine-tuned_content-words_model-label_diverse-beam_mnli_cond_pairs_tagged.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15246, 26)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "import pandas as pd\n",
    "import os\n",
    "from ast import literal_eval as make_tuple\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "# combine separate generations quickly\n",
    "# extension = 'csv'\n",
    "# all_filenames = [i for i in glob.glob('../'+ '*.{}'.format(extension))]\n",
    "# combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames])\n",
    "\n",
    "# df = combined_csv\n",
    "\n",
    "file_num = 3\n",
    "\n",
    "df = pd.read_csv('../output/MNLI/new/' + files[file_num])\n",
    "print(files[file_num])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15246, 26)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete mask-fills where there is no new token\n",
    "df = df[df['mask-filled'] != df['hypothesis']]\n",
    "\n",
    "# cut examples that don't change tokens \n",
    "# same_token = [(make_tuple(token_pairs)[0] == make_tuple(token_pairs)[1]) for token_pairs in df['token_changes']]\n",
    "# df['same-token'] = same_token\n",
    "# df = df[df['same-token'] == False]\n",
    "\n",
    "# cut the examples that reached threshold\n",
    "df = df[df['depth'] <= 9]\n",
    "\n",
    "# cut duplicate mask-filled sentences. only need one prem+hypo+hypo_mask for each pair.\n",
    "df = df.drop_duplicates(subset='mask-filled', keep=\"last\") \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for each data instance (original prem+hypo pair) gather top-k examples by similarity \n",
    "# topk = 5\n",
    "# print(len(df['line-num'].unique()))\n",
    "# df = df.groupby('line-num', as_index=False).apply(lambda x: x.nlargest(topk, 'Bert-Score'))\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Labels first\n",
    "df.loc[(df['label-changed'] == True) & (df['new-label-prob'] >= 0.8), 'flip-class'] = 'Certain-Flip'\n",
    "df.loc[(df['label-changed'] == True) & (df['new-label-prob'] < 0.8), 'flip-class'] = 'Uncertain-Flip'\n",
    "df.loc[(df['label-changed'] == False) & (df['new-label-prob'] >= 0.8), 'flip-class'] = 'Certain-Same'\n",
    "df.loc[(df['label-changed'] == False) & (df['new-label-prob'] < 0.8), 'flip-class'] = 'Uncertain-Same'\n",
    "\n",
    "# sort by Bert-Score and flip class\n",
    "df = df.sort_values(by=['flip-class','Bert-Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label \"interesting\" RTE data slices using slice function (SF) from Slice-based Learning/Polyjuice paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find \"interesting\" RTE data slices, add as filter\n",
    "# # use slices defined in paper. simple text matching.\n",
    "\n",
    "# temporal_prepositions = [\"after\", \"before\", \"past\"]\n",
    "# comparative_words = [\"more\", \"less\", \"better\", \"worse\", \"bigger\", \"smaller\"]\n",
    "# quantifiers = [\"all\", \"some\", \"none\"]\n",
    "# negation_words = [\"no\", \"not\", \"none\", \"no one\", \"nobody\", \"nothing\", \"neither\", \"nowhere\", \"never\", \"hardly\", \"scarcely\", \"barely\", \"doesnt\", \"isnt\", \"wasnt\", \"shouldnt\", \"wouldnt\", \"couldnt\", \"wont\", \"cant\", \"dont\"]\n",
    "\n",
    "# # if any slice words are in premise+hypothesis\n",
    "# total_SF = temporal_prepositions + comparative_words + quantifiers + negation_words\n",
    "\n",
    "# df['slice'] = (df['premise'] + df['hypothesis']).apply(lambda x: slice_function(total_SF, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputting\n",
    "df.to_csv('../output/MNLI/new/cleaned_' + files[file_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each Flip Class, get top 200 examples by Bert-Score, then sample 25 each.\n",
    "sample_df = pd.DataFrame()\n",
    "\n",
    "sample_df = sample_df.append(df[df['flip-class'] == 'Certain-Flip'].nlargest(200, 'Bert-Score').sample(25))\n",
    "sample_df = sample_df.append(df[df['flip-class'] == 'Uncertain-Flip'].nlargest(200, 'Bert-Score').sample(25))\n",
    "sample_df = sample_df.append(df[df['flip-class'] == 'Certain-Same'].nsmallest(200, 'Bert-Score').sample(25))\n",
    "sample_df = sample_df.append(df[df['flip-class'] == 'Uncertain-Same'].nsmallest(200, 'Bert-Score').sample(25))\n",
    "\n",
    "sample_df.to_csv('../output/MNLI/new/sample_' + files[file_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Sentence-Pair Classification Task\n",
    "\n",
    "Simply counting the direction of label flip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({('contradiction', 'contradiction'): 903, ('neutral', 'neutral'): 820, ('entailment', 'entailment'): 445, ('contradiction', 'entailment'): 317, ('entailment', 'contradiction'): 124, ('contradiction', 'neutral'): 120, ('neutral', 'contradiction'): 78, ('neutral', 'entailment'): 54, ('entailment', 'neutral'): 37})\n"
     ]
    }
   ],
   "source": [
    "from ast import literal_eval as make_tuple\n",
    "from collections import Counter\n",
    "\n",
    "CS_data = df[df['label-changed'] == True]\n",
    "\n",
    "# word changes that shift label\n",
    "# words = [make_tuple(w1) for w1 in CS_data['token_changes']]\n",
    "# change_count = Counter(words)\n",
    "\n",
    "# count of masked words\n",
    "# filled_words = [make_tuple(w1)[1] for w1 in CS_data['token_changes']]\n",
    "# filled_count = Counter(filled_words)\n",
    "\n",
    "# count of label switches in contrast set\n",
    "switches = zip(df['orig-label'], df['new-label'])\n",
    "switch_changes = Counter(switches)\n",
    "print(switch_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'contradiction': 1105, 'neutral': 977, 'entailment': 816})"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df['new-label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'contradiction': 1340, 'neutral': 952, 'entailment': 606})"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df['orig-label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({('contradiction', 'entailment'): 279, ('entailment', 'contradiction'): 109, ('contradiction', 'neutral'): 68, ('neutral', 'contradiction'): 65, ('neutral', 'entailment'): 32, ('entailment', 'neutral'): 19})\n"
     ]
    }
   ],
   "source": [
    "switches = zip(df.loc[df['flip-class'] == 'Certain-Flip', 'orig-label'], df.loc[df['flip-class'] == 'Certain-Flip', 'new-label'])\n",
    "switch_changes = Counter(switches)\n",
    "print(switch_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                           1110\n",
       "line-num                                                             3686\n",
       "pred-model                                                   RoBERTa-MNLI\n",
       "fill-model                                                     fine-tuned\n",
       "tokens-masked                                                 data-slices\n",
       "prepend-model                                                 model-label\n",
       "sampling-strategy                                            diverse-beam\n",
       "premise                 Today it is still very much complete, rivaled ...\n",
       "hypothesis              It is smaller and not as grand as St. Petersbu...\n",
       "mask-filled             It is small and not as grand as St. Petersburg...\n",
       "token_changes                                                       small\n",
       "fill_prob                                                          10.27%\n",
       "depth                                                                   3\n",
       "Word2Vec-Score                                                   0.995524\n",
       "Bert-Score                                                       0.994982\n",
       "gold-label                                                              0\n",
       "prepend-label                                                           0\n",
       "targeted-label                                                    neutral\n",
       "orig-label                                                     entailment\n",
       "new-label                                                   contradiction\n",
       "orig-label-prob                                                       0.5\n",
       "same-label-prob                                                      0.31\n",
       "new-label-prob                                                       0.48\n",
       "label-changed                                                        True\n",
       "same-label-prob-diff                                                 0.19\n",
       "flip-class                                                 Uncertain-Flip\n",
       "Name: 1093, dtype: object"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['flip-class'] == 'Uncertain-Flip'].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
