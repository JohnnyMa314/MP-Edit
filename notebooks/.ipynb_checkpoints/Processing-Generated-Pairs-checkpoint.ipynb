{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance Datasets Between Original Labels\n",
    "\n",
    "Sample **by MNLI index** from list of minimal pair edits of mask-filled sentence pairs until classes are balanced.\n",
    "\n",
    "With replacement **by MNLI index** and without replacement **by Generated Sentence Pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5000_fine-tuned_data-slices_gold-label_beam_mnli_cond_pairs_tagged.csv',\n",
       " '5000_fine-tuned_data-slices_gold-label_diverse-beam_mnli_cond_pairs_tagged.csv',\n",
       " '5000_fine-tuned_data-slices_model-label_beam_mnli_cond_pairs_tagged.csv',\n",
       " '5000_fine-tuned_data-slices_model-label_diverse-beam_mnli_cond_pairs_tagged.csv',\n",
       " 'sample_5000_fine-tuned_data-slices_gold-label_beam_mnli_cond_pairs_tagged.csv',\n",
       " 'sample_5000_fine-tuned_data-slices_gold-label_diverse-beam_mnli_cond_pairs_tagged.csv',\n",
       " 'sample_5000_fine-tuned_data-slices_model-label_beam_mnli_cond_pairs_tagged.csv',\n",
       " 'tagged_5000_fine-tuned_data-slices_gold-label_beam_mnli_cond_pairs_tagged.csv',\n",
       " 'tagged_5000_fine-tuned_data-slices_gold-label_diverse-beam_mnli_cond_pairs_tagged.csv',\n",
       " 'tagged_5000_fine-tuned_data-slices_model-label_beam_mnli_cond_pairs_tagged.csv']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = !ls MNLI/new\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2898, 25)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "import pandas as pd\n",
    "import os\n",
    "from ast import literal_eval as make_tuple\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "# combine separate generations quickly\n",
    "# extension = 'csv'\n",
    "# all_filenames = [i for i in glob.glob('../'+ '*.{}'.format(extension))]\n",
    "# combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames])\n",
    "\n",
    "# df = combined_csv\n",
    "\n",
    "file_num = 3\n",
    "\n",
    "df = pd.read_csv('./MNLI/new/' + files[file_num])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2898, 25)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete mask-fills where there is no new token\n",
    "df = df[df['mask-filled'] != df['hypothesis']]\n",
    "\n",
    "# cut examples that don't change tokens \n",
    "# same_token = [(make_tuple(token_pairs)[0] == make_tuple(token_pairs)[1]) for token_pairs in df['token_changes']]\n",
    "# df['same-token'] = same_token\n",
    "# df = df[df['same-token'] == False]\n",
    "\n",
    "# cut the examples that reached threshold\n",
    "df = df[df['depth'] <= 9]\n",
    "\n",
    "# cut duplicate mask-filled sentences. only need one prem+hypo+hypo_mask for each pair.\n",
    "df = df.drop_duplicates(subset='mask-filled', keep=\"last\") \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for each data instance (original prem+hypo pair) gather top-k examples by similarity \n",
    "# topk = 5\n",
    "# print(len(df['line-num'].unique()))\n",
    "# df = df.groupby('line-num', as_index=False).apply(lambda x: x.nlargest(topk, 'Bert-Score'))\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Labels first\n",
    "df.loc[(df['label-changed'] == True) & (df['new-label-prob'] >= 0.8), 'flip-class'] = 'Certain-Flip'\n",
    "df.loc[(df['label-changed'] == True) & (df['new-label-prob'] < 0.8), 'flip-class'] = 'Uncertain-Flip'\n",
    "df.loc[(df['label-changed'] == False) & (df['new-label-prob'] >= 0.8), 'flip-class'] = 'Certain-Same'\n",
    "df.loc[(df['label-changed'] == False) & (df['new-label-prob'] < 0.8), 'flip-class'] = 'Uncertain-Same'\n",
    "\n",
    "# sort by Bert-Score and flip class\n",
    "df = df.sort_values(by=['flip-class','Bert-Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label \"interesting\" RTE data slices using slice function (SF) from Slice-based Learning/Polyjuice paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'slice_function' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-47889e865047>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtotal_SF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemporal_prepositions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcomparative_words\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mquantifiers\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnegation_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'slice'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'premise'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hypothesis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_SF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4198\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4200\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-47889e865047>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtotal_SF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemporal_prepositions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcomparative_words\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mquantifiers\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnegation_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'slice'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'premise'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hypothesis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_SF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'slice_function' is not defined"
     ]
    }
   ],
   "source": [
    "# find \"interesting\" RTE data slices, add as filter\n",
    "# use slices defined in paper. simple text matching.\n",
    "\n",
    "temporal_prepositions = [\"after\", \"before\", \"past\"]\n",
    "comparative_words = [\"more\", \"less\", \"better\", \"worse\", \"bigger\", \"smaller\"]\n",
    "quantifiers = [\"all\", \"some\", \"none\"]\n",
    "negation_words = [\"no\", \"not\", \"none\", \"no one\", \"nobody\", \"nothing\", \"neither\", \"nowhere\", \"never\", \"hardly\", \"scarcely\", \"barely\", \"doesnt\", \"isnt\", \"wasnt\", \"shouldnt\", \"wouldnt\", \"couldnt\", \"wont\", \"cant\", \"dont\"]\n",
    "\n",
    "# if any slice words are in premise+hypothesis\n",
    "total_SF = temporal_prepositions + comparative_words + quantifiers + negation_words\n",
    "\n",
    "df['slice'] = (df['premise'] + df['hypothesis']).apply(lambda x: slice_function(total_SF, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputting\n",
    "df.to_csv('./MNLI/new/cleaned_' + files[file_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each Flip Class, get top 200 examples by Bert-Score, then sample 25 each.\n",
    "sample_df = pd.DataFrame()\n",
    "\n",
    "sample_df = sample_df.append(df[df['flip-class'] == 'Certain-Flip'].nlargest(200, 'Bert-Score').sample(25))\n",
    "sample_df = sample_df.append(df[df['flip-class'] == 'Uncertain-Flip'].nlargest(200, 'Bert-Score').sample(25))\n",
    "sample_df = sample_df.append(df[df['flip-class'] == 'Certain-Same'].nsmallest(200, 'Bert-Score').sample(25))\n",
    "sample_df = sample_df.append(df[df['flip-class'] == 'Uncertain-Same'].nsmallest(200, 'Bert-Score').sample(25))\n",
    "\n",
    "sample_df.to_csv('./MNLI/new/sample_' + files[file_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Sentence-Pair Classification Task\n",
    "\n",
    "Simply counting the direction of label flip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({('contradiction', 'contradiction'): 903, ('neutral', 'neutral'): 820, ('entailment', 'entailment'): 445, ('contradiction', 'entailment'): 317, ('entailment', 'contradiction'): 124, ('contradiction', 'neutral'): 120, ('neutral', 'contradiction'): 78, ('neutral', 'entailment'): 54, ('entailment', 'neutral'): 37})\n"
     ]
    }
   ],
   "source": [
    "from ast import literal_eval as make_tuple\n",
    "from collections import Counter\n",
    "\n",
    "CS_data = df[df['label-changed'] == True]\n",
    "\n",
    "# word changes that shift label\n",
    "# words = [make_tuple(w1) for w1 in CS_data['token_changes']]\n",
    "# change_count = Counter(words)\n",
    "\n",
    "# count of masked words\n",
    "# filled_words = [make_tuple(w1)[1] for w1 in CS_data['token_changes']]\n",
    "# filled_count = Counter(filled_words)\n",
    "\n",
    "# count of label switches in contrast set\n",
    "switches = zip(df['orig-label'], df['new-label'])\n",
    "switch_changes = Counter(switches)\n",
    "print(switch_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'contradiction': 1105, 'neutral': 977, 'entailment': 816})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df['new-label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'contradiction': 1340, 'neutral': 952, 'entailment': 606})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df['orig-label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({('contradiction', 'entailment'): 279, ('entailment', 'contradiction'): 109, ('contradiction', 'neutral'): 68, ('neutral', 'contradiction'): 65, ('neutral', 'entailment'): 32, ('entailment', 'neutral'): 19})\n"
     ]
    }
   ],
   "source": [
    "switches = zip(df.loc[df['flip-class'] == 'Certain-Flip', 'orig-label'], df.loc[df['flip-class'] == 'Certain-Flip', 'new-label'])\n",
    "switch_changes = Counter(switches)\n",
    "print(switch_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
